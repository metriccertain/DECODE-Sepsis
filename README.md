# DT1_Outcomes - MIMIC-IV as an external test set

## General info
SQL programs are copied from the [MIMIC concepts code repository](https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iv/concepts).  We used the code from the BigQuery folder so we had to modify slightly to work for SQLite.  Specifically, parts using date and date-time functions available in BigQuery were modified to use functions available in SQLite.

Rmd programs are used to derive the MIMIC-IV data and to write CSV files that are then read in by the Python programs

Python programs read in CSV data output above, get the data into the shape that the model expects, load the models, and score the MIMIC-IV data

### Quick start

Once you have copied the MIMIC-IV data one strategy for a quick start may be
  1. copy the two data folders into the ./mimic/ folder of this project so the relative paths will work.
  2. create the ./mimic/derived/v4/ and ./mimic/results/v4/ folders within this project

## Detailed statistical methods

The sample consists of adult (age ≥ 18) patients admitted to a critical care unit and meeting Sepsis-3 criteria, i.e. suspicion of infection along with SOFA score of 3 or greater, within the first 24 hours of admission. Data consisted of an internal development cohort (randomly split into training, test, and validation development cohorts), an internal non-random test cohort, and an external test cohort.

The development cohorts consisted of patients admitted to any of six ICUs at a single tertiary medical center (Mayo Clinic, Rochester, Minnesota) between 6/1/2011 and 3/31/2018. Patients who declined use of their medical records for research under Minnesota statute were excluded.

An internal hold-out non-random test cohort consisted of data from Mayo Clinic satisfying the same inclusion/exclusion criteria with date of admission between 5/31/2018 and 5/31/2021. The cutoff in time splitting development and internal hold-out non-random test data coincides with the transition of our institution’s electronic medical record to a new vendor. This represents a very strong validation set – with differences in time and in electronic medical record system as compared to the development data.

The external test cohort was derived from the MIMIC-IV database version 2.2 and consisted of adult patients admissions to the ICU who met Sepsis-3 criteria prior to or within the first 24 hours of admission in the years 2008 to 2019. This represents a validation set with differences in medical record systems, geography, and patient population.

Each ICU admission represented a unique unit of analysis. Our data were structured to develop a model that could output a prediction at any time in the first 24 hours of ICU admission. For practicality, the first 24 hours of ICU admission were discretized into 15-minute intervals. At a prediction time, the population is defined by patients alive and at risk (in the ICU) at that time.

The primary outcome was hospital death at any time or prolonged ICU length of stay greater than 14 days.

Time-independent variables collected included demographics and admission characteristics. Time-dependent variables included laboratory and vital signs values as well as treatments (e.g. vasopressors) and diagnoses (e.g. pneumonia), and were measured starting 6 hours prior to intensive care unit (ICU) admission throughout the first 24 hours of the admission or until discharge in cases where patients stayed less than 24 hours. Values were carried forward up to 6 hours or until updated measurements became available, and after 6 hours were considered missing and imputed to the mean. Variables included in the model were chosen a priori and are listed below and identified in figures in the accompanying manuscript.

Our model reflected an ensemble of 5 submodels including 2 convolutional neural network models (so named large and small), 2 long short term memory models (large and small), and a neural network model. The input to convolutional neural network and long short term memory models consisted of a length 31 vector of time-independent features and a 96-row by 38-column matrix of time-dependent features, with columns corresponding to features and rows corresponding to each 15-minute interval over the prior 24 hours. The model architecture of the convolutional neural network (CNN) is given in Figure 1 and described in the following. For each patient, at each 2-hour time point from time t = 2 hours through 24 hours in the ICU, the given vector/matrix input was constructed utilizing data beginning at time t – 24 hours and ending at time t. In other words, every 2 hours during their time in the ICU, each patient contributed an input which contained all the given information over the prior 24 hours. The interval of two hours was chosen a priori to balance the needs both for sufficient granularity and reasonable input data dimension. Data were considered unavailable prior to ICU admission (after the most recent value has been carried forward in the case of missing data as described above), so for observations where t < 24 hours, all rows corresponding to a time prior to ICU admission were set to -1 and masked. All features were min-max scaled according to the training data, which allows only validation and testing data to fall outside the range of 0 to 1. 

The convolutional models were derived by inputting the time-independent feature vectors into a neural network (NN) outputting a single hidden layer. The time-dependent feature matrices were input into a 1-dimensional convolutional neural network (1DCNN) with time-steps corresponding to rows (15-minute intervals) and channels corresponding to columns (features), and a flat hidden layer was output. The outputs from the NN and the 1DCNN were then concatenated and an additional fully connected dense hidden layer was added prior to the output layer. The recurrent models were derived in the same way, using a long- and short-term memory recurrent neural network (LSTM) instead of the 1DCNN.

For each model, large and small versions were considered; Figure 1 reflects the large version. An L2 regularization of 0.02 was applied to all parameters. The rectified linear unit (ReLU) activation function was used in all hidden layers with sigmoid activation used in output layers. In all models, the Adam optimizer with learning rate of 1E-4 was used, the loss function was binary cross-entropy, and models were trained until validation loss had not reduced for 100 epochs after a 50 epoch burn-in period. Batch size was 2000 in all cases. 

In addition to the convolutional models, a 40-node single hidden layer NN utilizing current values of all features (ie. a length 38 + 31 = 69 vector) was considered as a comparator useful to gauge the contribution of the time-dependent portions of the convolutional models. Performance of an ensemble model, which was the simple mean across all 5 model predictions, was assessed.

The development cohort was split into training (70%), validation (20%), and testing sets (10%). Since each ICU admission contributed multiple inputs to the analysis, the cohort was split such that data from a given admission would only go into one of the training, validation, or testing sets. Admissions in the training and validation sets were used to derive the model and assess model performance during training, respectively. Those admissions in the testing set were used to estimate model performance on unseen data. Prior to model fitting, training and validation data were shuffled randomly to help reduce autocorrelation. ICU admissions from the MIMIC-IV database were used as an external validation data set. Scripts used to derive the MIMIC-IV cohort and model input data have been provided.

Evaluation of performance was assessed at 15-minute intervals starting 2 hours after ICU admission through 24 hours in the test cohorts (internal non-random test and external test), demonstrating how the developed models can be applied at any timepoint after ICU admission despite model development using 2-hour intervals. Model performance was assessed using area under the receiver-operator-characteristic curve (AUROC) as well as visually plotting the receiver-operator-characteristic (ROC) curve and the precision-recall curve. Model calibration was assessed by grouping patients according to estimated probability (0 to <10%, 10 to <20%, …, 90 to 100%).

We compare to SAPS II and SOFA scores at 24 hours as each requires 24 hours of data before making a prediction. We include these in evaluation of ROC curves and precision-recall curves. AUROC is reported with 95% confidence intervals; comparison between our model and SAPS II and SOFA are evaluated using the DeLong test. Variable importance is described for the neural network submodel (one of the five submodels of the ensemble) by plotting mean absolute SHAP (SHapley Additive exPlanations) values.  SHAP values were estimated for 20 random observations at each of 3 time-points (8, 16, and 24 hours following admission) from the training data. 

### Features

Time-Independent (fixed at admission): age, sex, BMI, Charlson score; past medical history of: hypertension, myocardial infarction, chronic heart failure, peripheral vascular disease, dementia, cerebrovascular accident, chronic obstructive pulmonary disease, asthma, idiopathic lung disease, chronic pulmonary disease, connective tissue disease, diabetes, diabetes with complications, peptic ulcers, cirrhosis/mild liver disease, moderate/severe liver disease, hemi/paraplegia, moderate/severe kidney disease, solid tumor, leukemia, lymphoma, metastatic cancer and AIDS; and admission characteristics: pre-ICU LOS, surgical admission, and transplant.

Time-Dependent (updated as new data are available during the admission): interventions during admission: invasive ventilation, noninvasive ventilation, other ventilation (e.g., nasal cannula), ECMO, central/parenteral nutrition, norepinephrine, epinephrine, dobutamine, vasopressin and ringers lactate; ventilator and vital signs: PEEP, tidal volume, mean arterial pressure, heart rate, FiO2, SpO2, temperature, respiratory rate, Glasgow coma scale; diagnoses: pneumonia; and laboratory values: glucose, hemoglobin, potassium, sodium, platelet count, hematocrit, pH, creatinine, white blood cell count, BUN, HCO3, PaCO2, PaO2, lactate, INR, anion gap, and AST.
